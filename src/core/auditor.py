import logging
import asyncio
import json
from typing import List, Optional, Any, Dict
from pydantic import BaseModel, Field

from llama_index.core import VectorStoreIndex, QueryBundle
from llama_index.core.retrievers import BaseRetriever, VectorIndexRetriever, QueryFusionRetriever
from llama_index.core.postprocessor import LLMRerank
from llama_index.core.schema import NodeWithScore
from llama_index.llms.google_genai import GoogleGenAI

# Custom Imports
from src.config import settings
from src.core.prompts import (
    PROMPT_QUERY_GEN,
    PROMPT_CLASSIFY_TAGS,
    PROMPT_AUDIT_SYSTEM,
    PROMPT_AUDIT_USER_TEMPLATE,
    STYLE_CATEGORIES
)
from src.core.utils import (
    normalize_text,
    find_span_indices,
    deduplicate_violations
)

# Optional Reranker
try:
    from src.core.reranker import VertexAIRerank
except ImportError:
    print("âš ï¸ VertexAIRerank class not found. Re-ranking will be skipped.")
    VertexAIRerank = None

logger = logging.getLogger(__name__)

# --- PYDANTIC MODELS FOR STRUCTURED OUTPUT ---

class Violation(BaseModel):
    text: str = Field(description="Exact substring from the paragraph that violates the rule")
    explanation: str = Field(description="Why this violates the rule")
    suggested_fix: str = Field(description="Correction or 'omit'")
    rule_id: str = Field(description="ID of the violated rule (e.g. RULE_123)")
    rule_name: Optional[str] = Field(description="Name of the rule", default=None)
    source_url: Optional[str] = Field(description="URL of the rule", default=None)

class AuditResult(BaseModel):
    violations: List[Violation] = Field(default_factory=list)
    confident: bool = Field(description="True if the agent is certain about findings")
    needs_more_context: bool = Field(description="True if more rules are needed")
    additional_queries: List[str] = Field(default_factory=list, description="Queries to find missing rules")

class AuditorConfig(BaseModel):
    """Configuration for StyleAuditor."""
    model_name: str = settings.DEFAULT_MODEL
    temperature: float = 0.1
    initial_retrieval_count: int = settings.DEFAULT_INITIAL_RETRIEVAL_COUNT
    final_top_k: int = settings.DEFAULT_FINAL_TOP_K
    rerank_score_threshold: float = settings.DEFAULT_RERANK_SCORE_THRESHOLD
    aggregated_rule_limit: int = settings.DEFAULT_AGGREGATED_RULE_LIMIT
    min_sentence_length: int = settings.DEFAULT_MIN_SENTENCE_LENGTH
    max_agent_iterations: int = settings.DEFAULT_MAX_AGENT_ITERATIONS
    confidence_threshold: float = settings.DEFAULT_CONFIDENCE_THRESHOLD
    use_query_fusion: bool = True
    use_llm_rerank: bool = True

class StyleAuditor:
    """
    Unified Style Auditor.
    
    Refactored to support:
    - Async Execution
    - Dependency Injection (pass LLM/Retriever in)
    - Structured Outputs (Pydantic)
    """
    
    def __init__(
        self,
        llm: GoogleGenAI,
        retriever: Optional[BaseRetriever] = None,
        index: Optional[VectorStoreIndex] = None,
        config: Optional[AuditorConfig] = None,
    ):
        """
        Initialize the Auditor.
        
        Args:
            llm: Configured LLM instance (must support async/structured).
            retriever: Pre-configured retriever (optional).
            index: VectorStoreIndex to build retriever from (if retriever not provided).
            config: Auditor configuration parameters.
        """
        self.config = config or AuditorConfig()
        self.llm = llm
        
        # Setup Retriever
        if retriever:
            self.base_retriever = retriever
        elif index:
            self.base_retriever = VectorIndexRetriever(
                index=index,
                similarity_top_k=self.config.initial_retrieval_count,
                vector_store_query_mode="hybrid",
                sparse_top_k=10
            )
        else:
            raise ValueError("Must provide either 'retriever' or 'index' to StyleAuditor.")

        # Setup Advanced Retriever (Query Fusion)
        if self.config.use_query_fusion:
            self.retriever = QueryFusionRetriever(
                [self.base_retriever],
                llm=self.llm,
                similarity_top_k=self.config.initial_retrieval_count,
                num_queries=3,
                mode="reciprocal_rerank",
                use_async=True, # Enable async query gen
                verbose=True,
                query_gen_prompt=PROMPT_QUERY_GEN
            )
        else:
            self.retriever = self.base_retriever

        # Setup Rerankers
        self.llm_reranker = None
        if self.config.use_llm_rerank:
            self.llm_reranker = LLMRerank(
                choice_batch_size=10,
                top_n=self.config.final_top_k,
                llm=self.llm
            )

        self.vertex_reranker = None
        if VertexAIRerank:
            self.vertex_reranker = VertexAIRerank(
                project_id=settings.PROJECT_ID,
                location_id=settings.LLM_REGION,
                ranking_config="default_ranking_config",
                top_n=self.config.final_top_k
            )

        logger.info(f"ðŸ”§ Auditor initialized with Model: {self.config.model_name}")

    async def check_text(self, text: str) -> List[Dict]:
        """
        Main Async Entry Point.
        """
        if not text.strip():
            return []

        paragraphs = self._split_paragraphs(text)
        all_violations = []

        logger.info(f"ðŸ” Auditing {len(paragraphs)} paragraph(s)...")

        # Process paragraphs allowed (sequentially or parallel - sequential is safer for rate limits)
        for paragraph in paragraphs:
            paragraph_violations = await self._audit_paragraph_agentic(paragraph)
            if paragraph_violations:
                all_violations.extend(paragraph_violations)
        
        return deduplicate_violations(all_violations)

    def _split_paragraphs(self, text: str) -> List[str]:
        if not text:
            return []
        chunks = [chunk.strip() for chunk in text.split("\n\n") if chunk.strip()]
        return chunks if chunks else [text.strip()]

    async def _audit_paragraph_agentic(self, paragraph: str) -> List[Dict]:
        """
        Agentic audit loop with async execution and structured output.
        """
        # SKIP very short paragraphs
        if len(paragraph.split()) < self.config.min_sentence_length:
            return []

        # 1. Advanced Retrieval
        logger.info("ðŸ” Retrieving rules...")
        contexts = await self._retrieve_advanced(paragraph)
        
        # Deduplicate contexts
        unique_contexts = {c['id']: c for c in contexts}.values()
        contexts = list(unique_contexts)[:self.config.aggregated_rule_limit]
        
        violations = []
        
        # 2. Agent Loop
        for iteration in range(self.config.max_agent_iterations):
            logger.info(f"--- Iteration {iteration + 1}/{self.config.max_agent_iterations} ---")
            
            # Build Prompt
            prompt = self._build_prompt(paragraph, contexts, violations, iteration)
            
            # Call LLM with Structured Output
            try:
                # Use LlamaIndex's structured prediction if available, else manual
                # Assuming `llm.astructured_predict` exists in recent versions.
                # If NOT, we use `acomplete` and Pydantic program.
                # Since we are using GoogleGenAI directly, let's try the program approach or native if supported.
                # Simplest path: Use `llm.apredict` or similar if `astructured_predict` isn't ready.
                # But GoogleGenAI usually supports it.
                
                # Check if we can use sstructured_predict (LlamaIndex abstraction)
                # If not, fallback to JSON prompt + parse.
                # For safety in this refactor without checking installed version capabilities:
                # We will use the `prompt` which already asks for JSON, but we will ENFORCE it via `program` if possible.
                # Actually, `GoogleGenAI` class in LlamaIndex likely supports `astructured_predict`.
                
                response_obj = await self.llm.astructured_predict(
                    AuditResult,
                    prompt_template=prompt, 
                    # Note: prompt_template expects a PromptTemplate object usually, or string.
                    # Depending on version. Let's assume string works or wrap it.
                    # To be safe, let's use `acomplete` and parse, OR standard prompt.   
                )
                
                # The above `astructured_predict` takes a PromptTemplate. 
                # Let's fallback to `acomplete` with Pydantic generator if unsure about versions.
                # However, the user REQUESTED Pydantic.
                # Let's try `llm.astructured_predict(AuditResult, ...)`
                
            except Exception:
                # Fallback or distinct error handling
                # If `astructured_predict` fails or isn't found, try `acomplete` and parse.
                # For this implementation, let's assume valid environment.
                # BUT wait, `prompt` is a string. `astructured_predict` needs `PromptTemplate`.
                from llama_index.core import PromptTemplate
                tmpl = PromptTemplate(prompt)
                response_obj = await self.llm.astructured_predict(AuditResult, tmpl)

            if not response_obj:
                break
                
            # Process Result
            new_violations = response_obj.violations
            
            # Format and Extend
            formatted_violations = self._format_violations(new_violations, paragraph, contexts)
            if formatted_violations:
                violations.extend(formatted_violations)
            
            # Check Confidence
            if response_obj.confident and not response_obj.needs_more_context:
                logger.info("âœ… Agent is confident. Stopping.")
                break
            
            # Handle More Context
            if response_obj.additional_queries:
                logger.info(f"ðŸ” Requesting more context: {response_obj.additional_queries}")
                new_ctx = await self._collect_additional_contexts(response_obj.additional_queries)
                contexts.extend(new_ctx)

        return deduplicate_violations(violations)

    async def _retrieve_advanced(self, text: str) -> List[Dict]:
        """Async Advanced Retrieval."""
        # 0. Classify Tags (Optional Optimization)
        # Using simple method for now, can be async'd if we want.
        tags = await self._classify_text_async(text)
        tags_str = ", ".join(tags)
        
        query_text = text
        if tags:
            logger.info(f"ðŸ·ï¸ Tags: {tags_str}")
            query_text = f"Tags: {tags_str}. Content: {text}"

        # 1. Retrieve
        try:
            nodes = await self.retriever.aretrieve(query_text)
        except Exception as e:
            logger.error(f"Retrieval failed: {e}")
            return []

        # 2. Rerank (LLM)
        if self.config.use_llm_rerank and self.llm_reranker and nodes:
             try:
                 query_bundle = QueryBundle(query_str=text) 
                 # LLMRerank in older versions might not have `apostprocess_nodes`.
                 # Check if it does, else run sync in executor.
                 if hasattr(self.llm_reranker, "apostprocess_nodes"):
                    nodes = await self.llm_reranker.apostprocess_nodes(nodes, query_bundle=query_bundle)
                 else:
                    # Sync fallback
                    nodes = self.llm_reranker.postprocess_nodes(nodes, query_bundle=query_bundle)
             except Exception as e:
                 logger.warning(f"LLM Rerank failed: {e}")

        # 3. Rerank (Vertex)
        if self.vertex_reranker and nodes and not self.config.use_llm_rerank:
            try:
                # VertexAIRerank custom class likely sync? 
                # If we wrote it, we should check. Assuming sync for now.
                query_bundle = QueryBundle(query_str=text)
                nodes = self.vertex_reranker.postprocess_nodes(nodes, query_bundle=query_bundle)
            except Exception as e:
                 logger.warning(f"Vertex Rerank failed: {e}")

        return self._nodes_to_dicts(nodes, source_type="advanced_retrieval")

    async def _classify_text_async(self, text: str) -> List[str]:
        """Classify text using LLM."""
        if len(text.split()) < 5:
            return []
        
        prompt_str = PROMPT_CLASSIFY_TAGS.format(
            tags_list_str=", ".join(STYLE_CATEGORIES.split("\n")), 
            text_snippet=text[:1000]
        )
        try:
            resp = await self.llm.acomplete(prompt_str)
            found = [t.strip() for t in resp.text.split(',')]
            return found # In real version, filter against known tags
        except Exception:
            return []

    async def _collect_additional_contexts(self, queries: List[str]) -> List[Dict]:
        """Retrieve additional contexts for specific queries."""
        results = []
        # Simple parallel execution
        tasks = [self.base_retriever.aretrieve(q) for q in queries]
        node_lists = await asyncio.gather(*tasks, return_exceptions=True)
        
        for nodes in node_lists:
            if isinstance(nodes, list):
                # We can filter/rerank here strictly if needed
                # For speed, just take top K
                top_nodes = nodes[:self.config.final_top_k]
                results.extend(self._nodes_to_dicts(top_nodes, source_type="additional"))
        
        return results

    def _nodes_to_dicts(self, nodes: List[NodeWithScore], source_type="retrieved") -> List[Dict]:
        out = []
        for node in nodes:
            # Safely access metadata
            meta = node.metadata or {}
            out.append({
                "term": meta.get('term', 'Untitled Rule'),
                "text": meta.get('display_text', node.get_content()),
                "url": meta.get('url', ''),
                "score": node.score or 0.0,
                "source_type": source_type,
                "id": f"RULE_{node.node.node_id[:8]}"
            })
        return out

    def _build_prompt(self, paragraph, contexts, violations, iteration):
        context_lines = [
            f"{c['id']} | Rule: {c['term']}\nGuideline: {c['text']}" 
            for c in contexts
        ]
        context_block = "\n\n".join(context_lines) if context_lines else "No rules found."
        
        reflection_block = ""
        if iteration > 0 and violations:
             reflection_block = f"PREVIOUS FINDINGS: {len(violations)} violations found so far."

        # Return the FORMATTED prompt string
        # Note: We return the string, but `astructured_predict` needs a Template usually.
        # But wait, earlier we passed this result to `PromptTemplate`.
        # So we just return the string here.
        return PROMPT_AUDIT_SYSTEM + "\n" + PROMPT_AUDIT_USER_TEMPLATE.format(
            paragraph=paragraph,
            context_block=context_block,
            reflection_block=reflection_block
        )

    def _format_violations(self, pydantic_violations: List[Violation], paragraph: str, contexts: List[Dict]) -> List[Dict]:
        """Convert Pydantic violations to Dicts with indices."""
        formatted = []
        context_map = {c['id']: c for c in contexts}
        
        for v in pydantic_violations:
            start, end = find_span_indices(paragraph, v.text)
            
            # Enrich with source info
            rule_info = context_map.get(v.rule_id, {})
            
            formatted.append({
                "text": v.text,
                "violation": v.explanation,
                "correction": v.suggested_fix,
                "rule_id": v.rule_id,
                "rule_name": v.rule_name or rule_info.get('term'),
                "source_url": v.source_url or rule_info.get('url'),
                "paragraph": paragraph,
                "start_index": start,
                "end_index": end
            })
        return formatted
